# Summary

This Repository is a product of a personal learning exercise in understanding the fundamental structure, design and components involved in building a Large Language Model.
For both personal development in both Python skills as well as to gain understanding of a new frontier of technology I had little to no exposure in.

Before Starting this Project I had never done any previous research on any form of Neural Network, Machine-Learning, Deep Learning or any other related concepts.
In addition to this my experience with Python, was tangential at best.

## Credit

This Project was made while reading
Build a Large Language Model From Scratch
by Sebastian Raschka.

As It was created as a learning exercise, I do not claim credit for any pure originality of the material

While there may be slight differences in names, structures and breakdowns of the program produced by following the book
the underlying methodologies have been derived from said book, written by Sebastian Raschka, to who all credit is due.

As of 3/3/2025

# IMPORTANT

THIS REPOSITORY IS NOT PACKAGED TO BE PULLED AND RAN WITHOUT MANUAL CONFIGURATION AND SETUP.

Due to PyTorch, the files in this respoistory have been made with the assumption a CUDA compatible GPU has been used.

I am unaware of any performance, instability or other errors that may arise by using the CPU version of PyTorch 2.4.0

gpt_download.py must be ran to download the OPENAI gpt2.0 weights
